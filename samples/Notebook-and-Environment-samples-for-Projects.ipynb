{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPDCTL Samples for Notebooks and Environments in Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPDCTL is a command-line interface (CLI) you can use to manage the lifecycle of notebooks. By using the notebook CLI, you can automate the flow for creating notebooks and running notebook jobs, moving notebooks between projects in Watson Studio, and adding custom libraries to notebook runtime environments.   \n",
    "\n",
    "This notebook begins by showing you how to install and configure CPDCTL and is then split up into four sections with examples of how to use the commands for:\n",
    "\n",
    "- Creating notebooks and running notebook jobs\n",
    "- Creating Python scripts and running script jobs\n",
    "- Downloading notebooks from one project and uploading them to another project\n",
    "- Adding custom libraries to a notebook runtime environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Installing and configuring CPDCTL](#part1)\n",
    "- [1.1 Installing the latest version of CPDCTL](#part1.1)\n",
    "- [1.2 Adding CPD cluster configuration settings](#part1.2)\n",
    "\n",
    "[2. Demo 1: Creating a notebook asset and running a job](#part2)\n",
    "- [2.1 Creating a notebook asset](#part2.1)\n",
    "- [2.2 Running a job](#part2.2)\n",
    "\n",
    "[3. Demo 2: Creating a Python script asset and running a job](#part3)\n",
    "- [3.1 Creating a Python script asset](#part3.1)\n",
    "- [3.2 Running a job](#part3.2)\n",
    "\n",
    "[4. Demo 3: Downloading a notebook and uploading it to another project](#part4)\n",
    "- [4.1 Downloading a notebook](#part4.1)\n",
    "- [4.2 Uploading the notebook to another project](#part4.2)\n",
    "\n",
    "[5. Demo 4: Adding additional packages to custom environment](#part5)\n",
    "- [5.1 Creating a custom software specification](#part5.1)\n",
    "- [5.2 Adding additional packages](#part5.2)\n",
    "- [5.3 Creating a custom environment](#part5.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import platform\n",
    "import tarfile\n",
    "import zipfile\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Installing and configuring CPDCTL <a class=\"anchor\" id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Installing the latest version of CPDCTL <a class=\"anchor\" id=\"part1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the notebook and environment CLI commands, you need to install CPDCTL. Download the binary from the [CPDCTL GitHub respository](https://github.com/IBM/cpdctl/releases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the binary and then display the version number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<code>cpdctl</code> binary downloaded from: <a href=\"https://github.com/IBM/cpdctl/releases/download/v1.0.0/cpdctl_darwin_amd64.tar.gz\">cpdctl_darwin_amd64.tar.gz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PLATFORM = platform.system().lower()\n",
    "CPDCTL_ARCH = \"{}_amd64\".format(PLATFORM)\n",
    "CPDCTL_RELEASES_URL=\"https://api.github.com/repos/IBM/cpdctl/releases\"\n",
    "CWD = os.getcwd()\n",
    "PATH = os.environ['PATH']\n",
    "CPD_CONFIG = os.path.join(CWD, '.cpdctl.config.yml')\n",
    "\n",
    "response = requests.get(CPDCTL_RELEASES_URL)\n",
    "assets = response.json()[0]['assets']\n",
    "platform_asset = next(a for a in assets if CPDCTL_ARCH in a['name'])\n",
    "cpdctl_url = platform_asset['url']\n",
    "cpdctl_file_name = platform_asset['name']\n",
    "\n",
    "response = requests.get(cpdctl_url, headers={'Accept': 'application/octet-stream'})\n",
    "with open(cpdctl_file_name, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "    \n",
    "display(HTML('<code>cpdctl</code> binary downloaded from: <a href=\"{}\">{}</a>'.format(platform_asset['browser_download_url'], platform_asset['name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%env PATH={CWD}:{PATH}\n",
    "%env CPD_CONFIG={CPD_CONFIG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpdctl version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "if cpdctl_file_name.endswith('tar.gz'):\n",
    "    with tarfile.open(cpdctl_file_name, \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "elif cpdctl_file_name.endswith('zip'):\n",
    "    with zipfile.ZipFile(cpdctl_file_name, 'r') as zf:\n",
    "        zf.extractall()\n",
    "\n",
    "if CPD_CONFIG and os.path.exists(CPD_CONFIG):\n",
    "    os.remove(CPD_CONFIG)\n",
    "    \n",
    "version_r = ! cpdctl version\n",
    "CPDCTL_VERSION = version_r.s\n",
    "\n",
    "print(\"cpdctl version: {}\".format(CPDCTL_VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Adding CPD cluster configuration settings <a class=\"anchor\" id=\"part1.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can use CPDCTL, you need to add configuration settings. You only need to configure these settings once for the same IBM Cloud Pak for Data (CPD) user and cluster. Begin by entering your CPD credentials and the URL to the CPD cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPD_USER_NAME = #'YOUR CPD user name'\n",
    "CPD_USER_PASSWORD = #'YOUR CPD user password'\n",
    "CPD_URL = #'YOUR CPD CLUSTER URL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"cpd_user\" user to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cpdctl config user set cpd_user --username {CPD_USER_NAME} --password {CPD_USER_PASSWORD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"cpd\" cluster to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cpdctl config profile set cpd --url {CPD_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"cpd\" context to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cpdctl config context set cpd --profile cpd --user cpd_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List available contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m   \u001b[1mProfile\u001b[0m   \u001b[1mUser\u001b[0m       \u001b[1mCurrent\u001b[0m   \r\n",
      "\u001b[36;1mcpd\u001b[0m    cpd       cpd_user   *   \r\n"
     ]
    }
   ],
   "source": [
    "! cpdctl config context list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to the context you just created if it is not marked in the `Current` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to context \"cpd\".\r\n"
     ]
    }
   ],
   "source": [
    "! cpdctl config context use cpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List available projects in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m   \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1m09a3d37e-7572-4b54-88d5-44ae9f2e262a\u001b[0m   test2               2021-01-21T14:11:13.347Z                 []   \n",
      "\u001b[36;1m45c4b416-0700-46eb-be6e-7bb6bcd0a69f\u001b[0m   test                2021-01-21T14:10:21.116Z                 []   \n",
      "\u001b[36;1m5b36b5b9-98b3-4241-afa0-9ad85908ee19\u001b[0m   Default Notebooks   2021-01-14T17:33:05.918Z                 []   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl project list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the project in which you want to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project id: 09a3d37e-7572-4b54-88d5-44ae9f2e262a\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl project list --output json -j \"(resources[].metadata.guid)[0]\" --raw-output\n",
    "project_id = result.s\n",
    "print(\"project id: {}\".format(project_id))\n",
    "\n",
    "# You can also specify your project id directly:\n",
    "# project_id = \"Your project ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Demo 1: Creating a notebook asset and running a job <a class=\"anchor\" id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a Jupyter Notebook (.ipynb) file on your local system and you would like to run the code in the file as a job on a CPD cluster. This section shows you how to create a notebook asset and run a job on a CPD cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating a notebook asset<a class=\"anchor\" id=\"part2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, you need to create a notebook asset in your project. To create a notebook asset you need to specify:\n",
    "- The environment in which your notebook is to run\n",
    "- A notebook file (.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the environments in your project, filter them by their display name and get the ID of the environment in which your notebook will be run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Default Python 3.7\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: jupconda37-09a3d37e-7572-4b54-88d5-44ae9f2e262a\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the .ipynb file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_file_path = \"notebook/cpdctl-test-notebook.ipynb\"\n",
    "local_file_path = \"cpdctl-test-notebook.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path {remote_file_path} --file {local_file_path} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a notebook asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"cpdctl-test-notebook.ipynb\"\n",
    "runtime = {\n",
    "    'environment': env_id\n",
    "}\n",
    "runtime_json = json.dumps(runtime)\n",
    "originate = {\n",
    "    'type': 'blank'\n",
    "}\n",
    "originate_json = json.dumps(originate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook id: 9a0aa244-2573-4481-b37a-76fca9e00e64\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook create --file-reference {remote_file_path} --name {file_name} --project {project_id} --runtime '{runtime_json}' --originates-from '{originate_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "notebook_id = result.s\n",
    "print(\"notebook id: {}\".format(notebook_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Running a job <a class=\"anchor\" id=\"part2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating a notebook job, you need to create a version of your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version id: abef40d5-7577-4254-af41-69c9a2a9923b\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version create --notebook-id {notebook_id} --output json -j \"metadata.guid\" --raw-output\n",
    "version_id = result.s\n",
    "print(\"version id: {}\".format(version_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a notebook job, you need to give your job a name, add a description, and pass the notebook ID and environment ID you determined in [2.1](#part2.1). Additionally, you can add environment variables that will be used in your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"cpdctl-test-job\"\n",
    "job = {\n",
    "    'asset_ref': notebook_id, \n",
    "    'configuration': {\n",
    "        'env_id': env_id, \n",
    "        'env_variables': [\n",
    "            'foo=1', \n",
    "            'bar=2'\n",
    "        ]\n",
    "    }, \n",
    "    'description': 'my job', \n",
    "    'name': job_name\n",
    "}\n",
    "job_json = json.dumps(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job id: 20746052-166b-4fc9-949d-e8bbec863ffd\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job create --job '{job_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "job_id = result.s\n",
    "print(\"job id: {}\".format(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a notebook job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run = {\n",
    "    'configuration': {\n",
    "        'env_variables': [\n",
    "            'key1=value1', \n",
    "            'key2=value2'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "job_run_json = json.dumps(job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 850feaa4-b55d-4866-b1dc-55a1156460c5\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job run create --project-id {project_id} --job-id {job_id} --job-run '{job_run_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "run_id = result.s\n",
    "print(\"run id: {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the output of each cell in your .ipynb file by listing job run logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mtotal_count\u001b[0m   \u001b[1mresults\u001b[0m   \n",
      "\u001b[36;1m7\u001b[0m             Cell 1:   \n",
      "\u001b[36;1m7\u001b[0m             0   \n",
      "\u001b[36;1m7\u001b[0m             1   \n",
      "\u001b[36;1m7\u001b[0m             4   \n",
      "\u001b[36;1m7\u001b[0m             9   \n",
      "\u001b[36;1m7\u001b[0m             16   \n",
      "\u001b[36;1m7\u001b[0m                \n"
     ]
    }
   ],
   "source": [
    "! cpdctl job run logs --job-id {job_id} --run-id {run_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demo 2: Creating a Python script asset and running a job <a class=\"anchor\" id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a Python script (.py) on your local system and you would like to run the code in the script as a job on a CPD cluster. This section shows you how to create a Python script asset and run a job on a CPD cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creating a Python script asset<a class=\"anchor\" id=\"part3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the script (.py) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_file_path = \"script/test_script.py\"\n",
    "local_file_path = \"test_script.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path {remote_file_path} --file {local_file_path} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the metadata, entity and attachments of the script file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"name\": \"my_test_script\",\n",
    "    \"asset_type\": \"script\",\n",
    "    \"asset_category\": \"USER\",\n",
    "    \"origin_country\": \"us\"\n",
    "}\n",
    "metadata_json = json.dumps(metadata)\n",
    "\n",
    "entity = {\n",
    "    \"script\": {\n",
    "        \"language\": {\n",
    "            \"name\": \"python3\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "entity_json = json.dumps(entity)\n",
    "\n",
    "attachments = [\n",
    "    {\n",
    "        \"asset_type\": \"script\",\n",
    "        \"name\": \"my_test_script\",\n",
    "        \"description\": \"attachment for script\",\n",
    "        \"mime\": \"application/text\",\n",
    "        \"object_key\": remote_file_path\n",
    "    }\n",
    "]\n",
    "attachments_json = json.dumps(attachments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Python script asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script id: 7b4e1280-c2d1-4004-b15a-d619b5266efe\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl asset create  --metadata '{metadata_json}' --entity '{entity_json}' --attachments '{attachments_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "script_id = result.s\n",
    "print(\"script id: {}\".format(script_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Running a job<a class=\"anchor\" id=\"part3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to a notebook job, you need to specify the environment in which your script job is to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Default Python 3.7\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: jupconda37-09a3d37e-7572-4b54-88d5-44ae9f2e262a\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create a script job. To do this, you need to give your script job a name, a description, and pass the script ID and environment ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"cpdctl-test-job-for-script\"\n",
    "job = {\n",
    "    'asset_ref': script_id, \n",
    "    'configuration': {\n",
    "        'env_id': env_id, \n",
    "        'env_variables': [\n",
    "            'foo=1', \n",
    "            'bar=2'\n",
    "        ]\n",
    "    }, \n",
    "    'description': 'my script job', \n",
    "    'name': job_name\n",
    "}\n",
    "job_json = json.dumps(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job id: 0495fa5b-8b18-44c1-86e0-3d6a340405c7\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job create --job '{job_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "job_id = result.s\n",
    "print(\"job id: {}\".format(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your script job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run = {\n",
    "    'configuration': {\n",
    "        'env_variables': [\n",
    "            'key1=value1', \n",
    "            'key2=value2'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "job_run_json = json.dumps(job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: de481355-7791-43cd-8c65-dce744b101fa\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job run create --project-id {project_id} --job-id {job_id} --job-run '{job_run_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "run_id = result.s\n",
    "print(\"run id: {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show your script job run logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mtotal_count\u001b[0m   \u001b[1mresults\u001b[0m   \n",
      "\u001b[36;1m6\u001b[0m             25   \n",
      "\u001b[36;1m6\u001b[0m             36   \n",
      "\u001b[36;1m6\u001b[0m             49   \n",
      "\u001b[36;1m6\u001b[0m             64   \n",
      "\u001b[36;1m6\u001b[0m             81   \n",
      "\u001b[36;1m6\u001b[0m                \n"
     ]
    }
   ],
   "source": [
    "! cpdctl job run logs --job-id {job_id} --run-id {run_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demo 3: Downloading a notebook and uploading it to another project <a class=\"anchor\" id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a notebook in one project and would like to add a specific version of this notebook to another project. To do this, you first need to download the notebook file to your local system and then upload it to the other project. After that you need to create a notebook asset in your project by referencing the uploaded notebook file (.ipynb) and specifying the environment in which your notebook is to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Downloading a notebook <a class=\"anchor\" id=\"part4.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select which notebook version you want to download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List notebook versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mCreated\u001b[0m   \n",
      "\u001b[36;1mabef40d5-7577-4254-af41-69c9a2a9923b\u001b[0m   1611757174773   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl notebook version list --notebook-id {notebook_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the path in the storage volume to the notebook version that you want to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version id: abef40d5-7577-4254-af41-69c9a2a9923b\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version list --notebook-id {notebook_id} --output json -j \"(resources[].metadata.guid)[0]\" --raw-output\n",
    "version_id = result.s\n",
    "print(\"version id: {}\".format(version_id))\n",
    "\n",
    "# You can also specify your version id directly:\n",
    "# env_id = \"Your version ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version storage path: .notebook_versions/cpdctl-test-notebook_version_1611757174773.ipynb\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version get --notebook-id {notebook_id} --version-id {version_id} --output json -j \"entity.file_reference\" --raw-output\n",
    "version_storage_path = result.s\n",
    "print(\"version storage path: {}\".format(version_storage_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the noteboook asset with the specific version from the storage path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n",
      "Output written to my-new-notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "file_name = \"my-new-notebook.ipynb\"\n",
    "\n",
    "! cpdctl asset file download --path {version_storage_path} --output-file {file_name} --project-id {project_id} --raw-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Uploading the notebook to another project <a class=\"anchor\" id=\"part4.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the ID of the project to which you want to upload your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another project id: 45c4b416-0700-46eb-be6e-7bb6bcd0a69f\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl project list --output json -j \"(resources[].metadata.guid)[1]\" --raw-output\n",
    "project2_id = result.s\n",
    "print(\"another project id: {}\".format(project2_id))\n",
    "\n",
    "# You can also specify your another project id directly:\n",
    "# project2_id = \"Your another project ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the notebook file to this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "remote_file_path = \"notebook/{}\".format(file_name)\n",
    "\n",
    "! cpdctl asset file upload --path {remote_file_path} --file {file_name} --project-id {project2_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have uploaded the notebook file to the project, you need to specify the environment in which to run the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Default Python 3.7\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: jupconda37-45c4b416-0700-46eb-be6e-7bb6bcd0a69f\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project2_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create a notebook asset in this project by referencing the uploaded notebook file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"my-new-notebook-in-another-project.ipynb\"\n",
    "runtime = {\n",
    "    'environment': env_id\n",
    "}\n",
    "runtime_json = json.dumps(runtime)\n",
    "originate = {\n",
    "    'type': 'blank'\n",
    "}\n",
    "originate_json = json.dumps(originate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook id: 7c920b46-47a4-4ebf-9a88-f9c9024af0a3\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook create --file-reference {remote_file_path} --name {file_name} --project {project2_id} --originates-from '{originate_json}' --runtime '{runtime_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "notebook_id = result.s\n",
    "print(\"notebook id: {}\".format(notebook_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demo 4: Adding additional packages for custom environment <a class=\"anchor\" id=\"part5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a `conda-yml` file that lists your additional packages **or** you have a `pip-zip` file containing your custom packages, and you would like to install these packages in your custom environment. To do this, you need to:\n",
    "\n",
    "- Create a custom software specification\n",
    "- Add your custom packages\n",
    "- Create a custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creating a custom software specification <a class=\"anchor\" id=\"part5.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a custom software specification, you need to specify the base software specification that you want to customize. You can list all the software specifications in your project and choose one of them as the base software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                            \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m                                                                           \u001b[1mType\u001b[0m   \n",
      "\u001b[36;1m0062b8c9-8b7d-44a0-a9b9-46c416adcbd9\u001b[0m   default_py3.6                   2021-01-14T15:45:12.589Z   Default Python 3.6                                                                    software_specification   \n",
      "\u001b[36;1m069ea134-3346-5748-b513-49120e15d288\u001b[0m   pytorch-onnx_1.3-py3.7-edt      2021-01-14T15:45:12.605Z   Software specification for Pytorch 1.3.1 Elastic Distributed Training on Python 3.7   software_specification   \n",
      "\u001b[36;1m09c5a1d0-9c1e-4473-a344-eb7b665ff687\u001b[0m   scikit-learn_0.20-py3.6         2021-01-14T15:45:12.596Z   Software specification for Scikit-learn on Python 3.6                                 software_specification   \n",
      "\u001b[36;1m09f4cff0-90a7-5899-b9ed-1ef348aebdee\u001b[0m   spark-mllib_3.0-scala_2.12      2021-01-14T15:45:12.616Z   Machine Learning on Spark 3.0 with Scala 2.12                                         software_specification   \n",
      "\u001b[36;1m0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda\u001b[0m   ai-function_0.1-py3.6           2021-01-14T15:45:12.583Z   Software specification for AI function on Python 3.6                                  software_specification   \n",
      "\u001b[36;1m0e6e79df-875e-4f24-8ae9-62dcc2148306\u001b[0m   shiny-r3.6                      2021-01-14T15:45:12.607Z   R 3.6 with Shiny                                                                      software_specification   \n",
      "\u001b[36;1m10ac12d6-6b30-4ccd-8392-3e922c096a92\u001b[0m   pytorch_1.1-py3.6               2021-01-14T15:45:12.592Z   Software specification for Pytorch on Python 3.6                                      software_specification   \n",
      "\u001b[36;1m154010fa-5b3b-4ac1-82af-4d5ee5abbc85\u001b[0m   scikit-learn_0.22-py3.6         2021-01-14T15:45:12.597Z   Software specification for Scikit-learn on Python 3.6                                 software_specification   \n",
      "\u001b[36;1m1b70aec3-ab34-4b87-8aa0-a4a3c8296a36\u001b[0m   default_r3.6                    2021-01-14T15:45:12.606Z   Default R 3.6                                                                         software_specification   \n",
      "\u001b[36;1m2b73a275-7cbf-420b-a912-eae7f436e0bc\u001b[0m   tensorflow_1.15-py3.6           2021-01-14T15:45:12.598Z   Software specification for Tensorflow on Python 3.6                                   software_specification   \n",
      "\u001b[36;1m2c8ef57d-2687-4b7d-acce-01f94976dac1\u001b[0m   pytorch_1.2-py3.6               2021-01-14T15:45:12.592Z   Software specification for Pytorch on Python 3.6                                      software_specification   \n",
      "\u001b[36;1m2e51f700-bca0-4b0d-88dc-5c6791338875\u001b[0m   spark-mllib_2.3                 2021-01-14T15:45:12.608Z   Machine Learning on Spark 2.3 with Python 3.6                                         software_specification   \n",
      "\u001b[36;1m32983cea-3f32-4400-8965-dde874a8d67e\u001b[0m   pytorch-onnx_1.1-py3.6-edt      2021-01-14T15:45:12.593Z   Software specification for Pytorch EDT with ONNX on Python 3.6                        software_specification   \n",
      "\u001b[36;1m36507ebe-8770-55ba-ab2a-eafe787600e9\u001b[0m   spark-mllib_3.0-py37            2021-01-14T15:45:12.615Z   Machine Learning on Spark 3.0 with Python 3.7                                         software_specification   \n",
      "\u001b[36;1m390d21f8-e58b-4fac-9c55-d7ceda621326\u001b[0m   spark-mllib_2.4                 2021-01-14T15:45:12.611Z   Machine Learning on Spark 2.4 with Python 3.6                                         software_specification   \n",
      "\u001b[36;1m39e31acd-5f30-41dc-ae44-60233c80306e\u001b[0m   xgboost_0.82-py3.6              2021-01-14T15:45:12.598Z   Software specification for XGBoost on Python 3.6                                      software_specification   \n",
      "\u001b[36;1m40589d0e-7019-4e28-8daa-fb03b6f4fe12\u001b[0m   pytorch-onnx_1.2-py3.6-edt      2021-01-14T15:45:12.594Z   Software specification for Pytorch EDT with ONNX on Python 3.6                        software_specification   \n",
      "\u001b[36;1m435bfa8f-ddae-549a-826a-894368887231\u001b[0m   ai-function_0.2-py3.6           2021-01-14T15:45:12.582Z   Software specification for Python Functions on Python 3.6                             software_specification   \n",
      "\u001b[36;1m49403dff-92e9-4c87-a3d7-a42d0021c095\u001b[0m   spark-mllib_2.4-r_3.6           2021-01-14T15:45:12.610Z   Machine Learning on Spark 2.4 with R 3.6                                              software_specification   \n",
      "\u001b[36;1m4ff8d6c2-1343-4c18-85e1-689c965304d3\u001b[0m   xgboost_0.90-py3.6              2021-01-14T15:45:12.599Z   Software specification for XGBoost on Python 3.6                                      software_specification   \n",
      "\u001b[36;1m50f95b2a-bc16-43bb-bc94-b0bed208c60b\u001b[0m   pytorch-onnx_1.1-py3.6          2021-01-14T15:45:12.594Z   Software specification for Pytorch with ONNX on Python 3.6                            software_specification   \n",
      "\u001b[36;1m55a70f99-7320-4be5-9fb9-9edb5a443af5\u001b[0m   spark-mllib_2.4-scala_2.11      2021-01-14T15:45:12.610Z   Machine Learning on Spark 2.4 with Scala 2.11                                         software_specification   \n",
      "\u001b[36;1m5c2e37fa-80b8-5e77-840f-d912469614ee\u001b[0m   autoai-obm_2.0                  2021-01-14T15:45:12.608Z   Software specification for AutoAI OneButtonMachine on Spark                           software_specification   \n",
      "\u001b[36;1m5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b\u001b[0m   spss-modeler_18.1               2021-01-14T15:45:12.617Z   SPSS Modeler 18.1                                                                     software_specification   \n",
      "\u001b[36;1m632d4b22-10aa-5180-88f0-f52dfb6444d7\u001b[0m   autoai-kb_3.1-py3.7             2021-01-14T15:45:12.600Z   Software specification for AutoAI KaggleBot on Python 3.7                             software_specification   \n",
      "\u001b[36;1m687eddc9-028a-4117-b9dd-e57b36f1efa5\u001b[0m   spss-modeler_18.2               2021-01-14T15:45:12.618Z   SPSS Modeler 18.2                                                                     software_specification   \n",
      "\u001b[36;1m692a6a4d-2c4d-45ff-a1ed-b167ee55469a\u001b[0m   pytorch-onnx_1.2-py3.6          2021-01-14T15:45:12.595Z   Software specification for Pytorch with ONNX on Python 3.6                            software_specification   \n",
      "\u001b[36;1m75a3a4b0-6aa0-41b3-a618-48b1f56332a6\u001b[0m   do_12.9                         2021-01-14T15:45:12.580Z   Software specification for Decision Optimization                                      software_specification   \n",
      "\u001b[36;1m7abc992b-b685-532b-a122-a396a3cdbaab\u001b[0m   spark-mllib_2.4-py37            2021-01-14T15:45:12.609Z   Machine Learning on Spark 2.4 with Python 3.7                                         software_specification   \n",
      "\u001b[36;1m7bb3dbe2-da6e-4145-918d-b6d84aa93b6b\u001b[0m   caffe_1.0-py3.6                 2021-01-14T15:45:12.587Z   Caffe (community) on Python 3.6                                                       software_specification   \n",
      "\u001b[36;1m82c79ece-4d12-40e6-8787-a7b9e0f62770\u001b[0m   cuda-py3.6                      2021-01-14T15:45:12.588Z   Python 3.6 with CUDA                                                                  software_specification   \n",
      "\u001b[36;1m8c1a58c6-62b5-4dc4-987a-df751c2756b6\u001b[0m   hybrid_0.1                      2021-01-14T15:45:12.581Z   Watson Machine Learning Hybrid framework                                              software_specification   \n",
      "\u001b[36;1m8d5d8a87-a912-54cf-81ec-3914adaa988d\u001b[0m   pytorch-onnx_1.3-py3.7          2021-01-14T15:45:12.605Z   Software specification for Pytorch 1.3.1 on Python 3.7                                software_specification   \n",
      "\u001b[36;1m8d863266-7927-4d1e-97d7-56a7f4c0a19b\u001b[0m   caffe-ibm_1.0-py3.6             2021-01-14T15:45:12.588Z   Caffe (IBM) on Python 3.6                                                             software_specification   \n",
      "\u001b[36;1m902d0051-84bd-4af6-ab6b-8f6aa6fdeabb\u001b[0m   spss-modeler_17.1               2021-01-14T15:45:12.617Z   SPSS Modeler 17.1                                                                     software_specification   \n",
      "\u001b[36;1m9100fd72-8159-4eb9-8a0b-a87e12eefa36\u001b[0m   do_12.10                        2021-01-14T15:45:12.579Z   Software specification for Decision Optimization                                      software_specification   \n",
      "\u001b[36;1m9447fa8b-2051-4d24-9eef-5acb0e3c59f8\u001b[0m   do_py3.7                        2021-01-14T15:45:12.604Z   Python 3.7 with Decision Optimization                                                 software_specification   \n",
      "\u001b[36;1m94bb6052-c837-589d-83f1-f4142f219e32\u001b[0m   spark-mllib_3.0-r_3.6           2021-01-14T15:45:12.616Z   Machine Learning on Spark 3.0 with R 3.6                                              software_specification   \n",
      "\u001b[36;1m9a44990c-1aa1-4c7d-baf8-c4099011741c\u001b[0m   cuda-py3.7                      2021-01-14T15:45:12.602Z   Python 3.7 with CUDA                                                                  software_specification   \n",
      "\u001b[36;1m9b3f9040-9cee-4ead-8d7a-780600f542f7\u001b[0m   hybrid_0.2                      2021-01-14T15:45:12.582Z   Watson Machine Learning Hybrid framework                                              software_specification   \n",
      "\u001b[36;1maf10f35f-69fa-5d66-9bf5-acb58434263a\u001b[0m   autoai-obm_2.0 with Spark 3.0   2021-01-14T15:45:12.613Z   Software specification for AutoAI OneButtonMachine on Spark                           software_specification   \n",
      "\u001b[36;1mc4032338-2a40-500a-beef-b01ab2667e27\u001b[0m   tensorflow_2.1-py3.7            2021-01-14T15:45:12.606Z   Software specification for Tensorflow 2.1 on Python 3.7                               software_specification   \n",
      "\u001b[36;1md139f196-e04b-5d8b-9140-9a10ca1fa91a\u001b[0m   autoai-kb_3.0-py3.6             2021-01-14T15:45:12.586Z   Software specification for AutoAI KaggleBot on Python 3.6                             software_specification   \n",
      "\u001b[36;1md82546d5-dd78-5fbb-9131-2ec309bc56ed\u001b[0m   spark-mllib_3.0-py36            2021-01-14T15:45:12.614Z   Machine Learning on Spark 3.0 with Python 3.6                                         software_specification   \n",
      "\u001b[36;1me4429883-c883-42b6-87a8-f419d64088cd\u001b[0m   default_py3.7                   2021-01-14T15:45:12.603Z   Default Python 3.7                                                                    software_specification   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment software-specification list --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base software specification id: e4429883-c883-42b6-87a8-f419d64088cd\n"
     ]
    }
   ],
   "source": [
    "base_sw_spec_name = \"Default Python 3.7\"\n",
    "query_string = \"(resources[?metadata.description == '{}'].metadata.asset_id)[0]\".format(base_sw_spec_name)\n",
    "\n",
    "result = ! cpdctl environment software-specification list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "base_sw_spec_id = result.s\n",
    "print(\"base software specification id: {}\".format(base_sw_spec_id))\n",
    "\n",
    "# You can also specify your base software specification id directly:\n",
    "# based_sw_spec_id = \"Your base software specification ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sw_spec_name = \"my_sw_spec\"\n",
    "\n",
    "base_sw_spec = {\n",
    "    'guid': base_sw_spec_id\n",
    "}\n",
    "\n",
    "base_sw_spec_json = json.dumps(base_sw_spec)\n",
    "\n",
    "sw_conf = {}\n",
    "sw_conf_json = json.dumps(sw_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom software specification id: d083a07d-42e0-4486-b839-bd019d71ef73\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment software-specification create --project-id {project_id} --name {custom_sw_spec_name} --base-software-specification '{base_sw_spec_json}' --software-configuration '{sw_conf_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "custom_sw_spec_id = result.s\n",
    "print(\"custom software specification id: {}\".format(custom_sw_spec_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Adding additional packages <a class=\"anchor\" id=\"part5.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a package extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_name = \"my_test_packages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package extension id: 73f7267e-bc02-42fc-ae5f-a54a32a27fc6\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment package-extension create --name {pkg_name} --type \"conda_yml\" --project-id {project_id}  --output json\n",
    "pkg_ext_id = json.loads(result.s)['metadata']['asset_id']\n",
    "print(\"package extension id: {}\".format(pkg_ext_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the path to where you want to upload the additional packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path where asset should be uploaded: package_extension/my_test_packages_An_bkImwj2.yml\n"
     ]
    }
   ],
   "source": [
    "pkg_ext_href = json.loads(result.s)['entity']['package_extension']['href'].split('/')[4].split('?')[0]\n",
    "remote_pkg_path = \"package_extension/{}\".format(pkg_ext_href)\n",
    "print(\"path where asset should be uploaded: {}\".format(remote_pkg_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a conda-yaml file listing additional packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_yaml = \"\"\"\n",
    "channels:\n",
    "  - defaults\n",
    "\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - fuzzywuzzy\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('my-pkg-ext.yaml', 'w') as f:\n",
    "    f.write(my_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload additional packages to the path returned in the previous command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_pkg_path = \"./my-pkg-ext.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path \"{remote_pkg_path}\" --file {local_pkg_path} --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment package-extension upload-complete --package-extension-id {pkg_ext_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the package extension into the custom software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment software-specification add-package-extensions --software-specification-id {custom_sw_spec_id} --package-extension-id {pkg_ext_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Creating a custom environment <a class=\"anchor\" id=\"part5.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the hardware specifications in your project and choose one that fits your custom environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m            \u001b[1mDescription\u001b[0m                                                                                                                              \u001b[1mType\u001b[0m   \n",
      "\u001b[36;1m5a1f0e64-e420-55ce-bd7a-f6d00bb942cf\u001b[0m   ML              A hardware specification providing 4 CPU cores and 32 GiB of memory.                                                                     hardware_specification   \n",
      "\u001b[36;1ma02f3ab5-6964-4f06-a870-c7cc69187895\u001b[0m   V100x2          A hardware specification providing 52 CPU cores and 96 GiB of memory with 2 Nvidia v100 GPUs.                                            hardware_specification   \n",
      "\u001b[36;1ma6c4923b-b8e4-444c-9f43-8a7ec3020110\u001b[0m   L               A hardware specification providing 8 CPU cores and 32 GiB of memory.                                                                     hardware_specification   \n",
      "\u001b[36;1mac59d20a-9c7c-4504-a853-788ef35969da\u001b[0m   Default Spark   A hardware specification for Spark with 1 CPU and 4 GiB of memory for master and worker nodes, with 2 workers.                           hardware_specification   \n",
      "\u001b[36;1mb128f957-581d-46d0-95b6-8af5cd5be580\u001b[0m   XXS             A hardware specification providing one CPU core and 2 GiB of memory.                                                                     hardware_specification   \n",
      "\u001b[36;1mb2232f7a-bfad-4822-9bce-6ba1af49217a\u001b[0m   M-Spark         A hardware specification for Spark service with 2 CPU and 8 GiB of memory for master and 2 CPU and 8 GiB of memory for worker nodes.     hardware_specification   \n",
      "\u001b[36;1mb305a34b-acb5-4850-a44a-f1f15e304a20\u001b[0m   V100x4          A hardware specification providing 104 CPU cores and 192 GiB of memory with 4 Nvidia v100 GPUs.                                          hardware_specification   \n",
      "\u001b[36;1mc076e82c-b2a7-4d20-9c0f-1f0c2fdf5a24\u001b[0m   M               A hardware specification providing 4 CPU cores and 16 GiB of memory.                                                                     hardware_specification   \n",
      "\u001b[36;1mc1791762-1333-4dd3-b7bb-228ae287da31\u001b[0m   XL-Spark        A hardware specification for Spark service with 3 CPU and 12 GiB of memory for master and 4 CPU and 12 GiB of memory for worker nodes.   hardware_specification   \n",
      "\u001b[36;1mcf70f086-916d-4684-91a7-264c49c6d425\u001b[0m   K80             A hardware specification providing 4 CPU cores and 48 GiB of memory with 1 Nvidia K80 GPU.                                               hardware_specification   \n",
      "\u001b[36;1md0aa1ae8-a889-42e2-a099-041b604b9289\u001b[0m   XL              A hardware specification providing 16 CPU cores and 64 GiB of memory.                                                                    hardware_specification   \n",
      "\u001b[36;1md0f52aa1-4312-40f6-ad84-f16cf5c6da9e\u001b[0m   K80x2           A hardware specification providing 8 CPU cores and 96 GiB of memory with 2 Nvidia K80 GPUs.                                              hardware_specification   \n",
      "\u001b[36;1md92943ba-9f47-407d-9280-c85281687a1e\u001b[0m   S-Spark         A hardware specification for Spark service with 1 CPU and 4 GiB of memory for master and 2 CPU and 4 GiB of memory for worker nodes.     hardware_specification   \n",
      "\u001b[36;1me18b1866-e8fa-49c8-9aa5-dfaaed6ffa43\u001b[0m   XS-Spark        A hardware specification for Spark with 1 CPU and 4 GiB of memory for master and worker nodes.                                           hardware_specification   \n",
      "\u001b[36;1me7ed1d6c-2e89-42d7-aed5-863b972c1d2b\u001b[0m   S               A hardware specification providing 2 CPU cores and 8 GiB of memory.                                                                      hardware_specification   \n",
      "\u001b[36;1mec104857-0389-4649-af8e-971fc11982d0\u001b[0m   K80x4           A hardware specification providing 16 CPU cores and 192 GiB of memory with 4 Nvidia K80 GPUs.                                            hardware_specification   \n",
      "\u001b[36;1mf132f14a-6c0f-4570-b87c-98ad1e297953\u001b[0m   L-Spark         A hardware specification for Spark service with 2 CPU and 8 GiB of memory for master and 4 CPU and 9 GiB of memory for worker nodes.     hardware_specification   \n",
      "\u001b[36;1mf327bdf7-5634-43d8-b1e3-445afeaf18b9\u001b[0m   V100            A hardware specification providing 26 CPU cores and 48 GiB of memory with 1 Nvidia v100 GPU.                                             hardware_specification   \n",
      "\u001b[36;1mf3ebac7d-0a75-410c-8b48-a931428cc4c5\u001b[0m   XS              A hardware specification providing one CPU core and 4 GiB of memory.                                                                     hardware_specification   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment hardware-specification list --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hardware specification id: f3ebac7d-0a75-410c-8b48-a931428cc4c5\n"
     ]
    }
   ],
   "source": [
    "hw_spec_keyword_1 = \"one CPU core\"\n",
    "hw_spec_keyword_2 = \"4 GiB of memory\"\n",
    "query_string = \"(resources[?contains(metadata.description, '{}') && contains(metadata.description, '{}')].metadata.asset_id)[0]\".format(hw_spec_keyword_1, hw_spec_keyword_2)\n",
    "\n",
    "result = ! cpdctl environment hardware-specification list --project-id {project_id}  --output json -j \"{query_string}\" --raw-output\n",
    "hw_spec_id = result.s\n",
    "print(\"hardware specification id: {}\".format(hw_spec_id))\n",
    "\n",
    "# You can also specify your hardware specification id directly:\n",
    "# hw_spec_id = \"Your base software specification ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom environment by specifying the hardware specification, the custom software specification and the tool specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"my_custom_env\"\n",
    "hw_spec = {\n",
    "    'guid': hw_spec_id\n",
    "}\n",
    "custom_sw_spec = {\n",
    "    'guid': custom_sw_spec_id\n",
    "}\n",
    "custom_sw_spec_json = json.dumps(custom_sw_spec)\n",
    "tool_spec = {\n",
    "    'supported_kernels': [{\n",
    "        'language': 'python', \n",
    "        'version': '3.7', \n",
    "        'display_name': 'Python 3.7'\n",
    "    }]\n",
    "}\n",
    "hw_spec_json = json.dumps(hw_spec)\n",
    "tool_spec_json = json.dumps(tool_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom environment id: 2b18f3e4-34ca-45b6-8f8e-49d34551b919\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment create --project-id {project_id} --type \"notebook\" --name {env_name} --display-name {env_name} --hardware-specification '{hw_spec_json}' --software-specification '{custom_sw_spec_json}' --tools-specification '{tool_spec_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "custom_env_id = result.s\n",
    "print(\"custom environment id: {}\".format(custom_env_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use this custom environment when you create a new notebook asset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
