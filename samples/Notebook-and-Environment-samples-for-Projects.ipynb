{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPDCTL Samples for Notebooks and Environments in Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPDCTL is a command-line interface (CLI) you can use to manage the lifecycle of notebooks. By using the notebook CLI, you can automate the flow for creating notebooks and running notebook jobs, moving notebooks between projects in Watson Studio, and adding custom libraries to notebook runtime environments.   \n",
    "\n",
    "This notebook begins by showing you how to install and configure CPDCTL and is then split up into four sections with examples of how to use the commands for:\n",
    "\n",
    "- Creating notebooks and running notebook jobs\n",
    "- Creating Python scripts and running script jobs\n",
    "- Downloading notebooks from one project and uploading them to another project\n",
    "- Adding custom libraries to a notebook runtime environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Installing and configuring CPDCTL](#part1)\n",
    "- [1.1 Installing the latest version of CPDCTL](#part1.1)\n",
    "- [1.2 Adding CPD cluster configuration settings](#part1.2)\n",
    "\n",
    "[2. Demo 1: Creating a notebook asset and running a job](#part2)\n",
    "- [2.1 Creating a notebook asset](#part2.1)\n",
    "- [2.2 Running a job](#part2.2)\n",
    "\n",
    "[3. Demo 2: Creating a Python script asset and running a job](#part3)\n",
    "- [3.1 Creating a Python script asset](#part3.1)\n",
    "- [3.2 Running a job](#part3.2)\n",
    "\n",
    "[4. Demo 3: Downloading a notebook and uploading it to another project](#part4)\n",
    "- [4.1 Downloading a notebook](#part4.1)\n",
    "- [4.2 Uploading the notebook to another project](#part4.2)\n",
    "\n",
    "[5. Demo 4: Adding additional packages to custom environment](#part5)\n",
    "- [5.1 Creating a custom software specification](#part5.1)\n",
    "- [5.2 Adding additional packages](#part5.2)\n",
    "- [5.3 Creating a custom environment](#part5.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/4n2vyk5x2431h86n7f402gcr0000gn/T/ipykernel_79895/1628720105.py:8: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import platform\n",
    "import tarfile\n",
    "import zipfile\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Installing and configuring CPDCTL <a class=\"anchor\" id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Installing the latest version of CPDCTL <a class=\"anchor\" id=\"part1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the notebook and environment CLI commands, you need to install CPDCTL. Download the binary from the [CPDCTL GitHub respository](https://github.com/IBM/cpdctl/releases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the binary and then display the version number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<code>cpdctl</code> binary downloaded from: <a href=\"https://github.com/IBM/cpdctl/releases/download/v1.4.68/cpdctl_darwin_amd64.tar.gz\">cpdctl_darwin_amd64.tar.gz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PLATFORM = platform.system().lower()\n",
    "CPDCTL_ARCH = \"{}_amd64\".format(PLATFORM)\n",
    "CPDCTL_RELEASES_URL=\"https://api.github.com/repos/IBM/cpdctl/releases\"\n",
    "CWD = os.getcwd()\n",
    "PATH = os.environ['PATH']\n",
    "CPD_CONFIG = os.path.join(CWD, '.cpdctl.config.yml')\n",
    "\n",
    "response = requests.get(CPDCTL_RELEASES_URL)\n",
    "assets = response.json()[0]['assets']\n",
    "platform_asset = next(a for a in assets if CPDCTL_ARCH in a['name'])\n",
    "cpdctl_url = platform_asset['url']\n",
    "cpdctl_file_name = platform_asset['name']\n",
    "\n",
    "response = requests.get(cpdctl_url, headers={'Accept': 'application/octet-stream'})\n",
    "with open(cpdctl_file_name, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "    \n",
    "display(HTML('<code>cpdctl</code> binary downloaded from: <a href=\"{}\">{}</a>'.format(platform_asset['browser_download_url'], platform_asset['name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%env PATH={CWD}:{PATH}\n",
    "%env CPD_CONFIG={CPD_CONFIG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpdctl version: 1.4.68 (20231030150348)\n"
     ]
    }
   ],
   "source": [
    "if cpdctl_file_name.endswith('tar.gz'):\n",
    "    with tarfile.open(cpdctl_file_name, \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "elif cpdctl_file_name.endswith('zip'):\n",
    "    with zipfile.ZipFile(cpdctl_file_name, 'r') as zf:\n",
    "        zf.extractall()\n",
    "\n",
    "if CPD_CONFIG and os.path.exists(CPD_CONFIG):\n",
    "    os.remove(CPD_CONFIG)\n",
    "    \n",
    "version_r = ! cpdctl version\n",
    "CPDCTL_VERSION = version_r.s\n",
    "\n",
    "print(\"cpdctl version: {}\".format(CPDCTL_VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Adding CPD cluster configuration settings <a class=\"anchor\" id=\"part1.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can use CPDCTL, you need to add configuration settings. You only need to configure these settings once for the same IBM Cloud Pak for Data (CPD) user and cluster. Begin by entering your CPD credentials and the URL to the CPD cluster.<br>**Note**: when running this notebook inside IBM Cloud Pak for Data (CP4D) cluster, cpdctl takes advantage of [zero-configuration mode](https://github.com/IBM/cpdctl#zero-configuration) which means it can connect to the CP4D without explicit configuration. In that case the cells below that set credential and URL variables as well as cells that run `cpdctl config ...` commands can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPD_USER_NAME = #'YOUR CPD user name'\n",
    "CPD_USER_PASSWORD = #'YOUR CPD user password'\n",
    "CPD_URL = #'YOUR CPD CLUSTER URL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"cpd_user\" user to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cpdctl config user set cpd_user --username {CPD_USER_NAME} --password {CPD_USER_PASSWORD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"cpd\" cluster to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cpdctl config profile set cpd --url {CPD_URL} --user cpd_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List available profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m   \u001b[1mType\u001b[0m      \u001b[1mUser\u001b[0m       \u001b[1mURL\u001b[0m                                            \u001b[1mIBM Cloud CLI config\u001b[0m   \u001b[1mRegion\u001b[0m   \u001b[1mCurrent\u001b[0m\n",
      "\u001b[36;1mcpd\u001b[0m    private   cpd_user   https://cpd-dev.apps.midgard.cp.fyre.ibm.com                                   *\n"
     ]
    }
   ],
   "source": [
    "! cpdctl config profile list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to the profile you just created if it is not marked in the `Current` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to profile \"cpd\".\n"
     ]
    }
   ],
   "source": [
    "! cpdctl config profile use cpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List available projects in profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m    \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m\n",
      "\u001b[36;1mbe7e848d-1a02-4282-b60a-1a728cd9cb70\u001b[0m   test    2023-11-22T15:02:56.339Z   \n",
      "\u001b[36;1m277c4bc5-2665-49fc-b33d-ce17fe9610fd\u001b[0m   test2   2023-12-05T18:07:09.694Z   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl project list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the project in which you want to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project id: be7e848d-1a02-4282-b60a-1a728cd9cb70\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl project list --output json -j \"(resources[].metadata.guid)[0]\" --raw-output\n",
    "project_id = result.s\n",
    "print(\"project id: {}\".format(project_id))\n",
    "\n",
    "# You can also specify your project id directly:\n",
    "# project_id = \"Your project ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Demo 1: Creating a notebook asset and running a job <a class=\"anchor\" id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a Jupyter Notebook (.ipynb) file on your local system and you would like to run the code in the file as a job on a CPD cluster. This section shows you how to create a notebook asset and run a job on a CPD cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating a notebook asset<a class=\"anchor\" id=\"part2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, you need to create a notebook asset in your project. To create a notebook asset you need to specify:\n",
    "- The environment in which your notebook is to run\n",
    "- A notebook file (.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the environments in your project, filter them by their display name and get the ID of the environment in which your notebook will be run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Runtime 23.1 on Python 3.10\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: rt231py-be7e848d-1a02-4282-b60a-1a728cd9cb70\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the .ipynb file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_file_path = \"notebook/cpdctl-test-notebook.ipynb\"\n",
    "local_file_path = \"cpdctl-test-notebook.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path {remote_file_path} --file {local_file_path} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a notebook asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"cpdctl-test-notebook.ipynb\"\n",
    "runtime = {\n",
    "    'environment': env_id\n",
    "}\n",
    "runtime_json = json.dumps(runtime)\n",
    "originate = {\n",
    "    'type': 'blank'\n",
    "}\n",
    "originate_json = json.dumps(originate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook id: a8f8c4de-dad8-430e-86f7-423fbb862a42\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook create --file-reference {remote_file_path} --name {file_name} --project-id {project_id} --runtime '{runtime_json}' --originates-from '{originate_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "notebook_id = result.s\n",
    "print(\"notebook id: {}\".format(notebook_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Running a job <a class=\"anchor\" id=\"part2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating a notebook job, you need to create a version of your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version id: 1aa9f73f-fcdd-41d0-bbbb-64105c8ee369\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version create --notebook-id {notebook_id} --output json -j \"metadata.guid\" --raw-output\n",
    "version_id = result.s\n",
    "print(\"version id: {}\".format(version_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a notebook job, you need to give your job a name, add a description, and pass the notebook ID and environment ID you determined in [2.1](#part2.1). Additionally, you can add environment variables that will be used in your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"cpdctl-test-job\"\n",
    "job = {\n",
    "    'asset_ref': notebook_id, \n",
    "    'configuration': {\n",
    "        'env_id': env_id, \n",
    "        'env_variables': [\n",
    "            'foo=1', \n",
    "            'bar=2'\n",
    "        ]\n",
    "    }, \n",
    "    'description': 'my job', \n",
    "    'name': job_name\n",
    "}\n",
    "job_json = json.dumps(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job id: 0dd5dc64-b139-484c-be9d-b881f6554729\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job create --job '{job_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "job_id = result.s\n",
    "print(\"job id: {}\".format(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a notebook job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run = {\n",
    "    'configuration': {\n",
    "        'env_variables': [\n",
    "            'key1=value1', \n",
    "            'key2=value2'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "job_run_json = json.dumps(job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: a0f7b7c5-39af-4a77-acbf-b4569d54da44\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job run create --project-id {project_id} --job-id {job_id} --job-run '{job_run_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "run_id = result.s\n",
    "print(\"run id: {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the output of each cell in your .ipynb file by listing job run logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "Cell 1:\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cpdctl job run logs --job-id {job_id} --run-id {run_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demo 2: Creating a Python script asset and running a job <a class=\"anchor\" id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a Python script (.py) on your local system and you would like to run the code in the script as a job on a CPD cluster. This section shows you how to create a Python script asset and run a job on a CPD cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creating a Python script asset<a class=\"anchor\" id=\"part3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the script (.py) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_file_path = \"script/test_script.py\"\n",
    "local_file_path = \"test_script.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path {remote_file_path} --file {local_file_path} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the metadata, entity and attachments of the script file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"name\": \"my_test_script\",\n",
    "    \"asset_type\": \"script\",\n",
    "    \"asset_category\": \"USER\",\n",
    "    \"origin_country\": \"us\"\n",
    "}\n",
    "metadata_json = json.dumps(metadata)\n",
    "\n",
    "entity = {\n",
    "    \"script\": {\n",
    "        \"language\": {\n",
    "            \"name\": \"python3\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "entity_json = json.dumps(entity)\n",
    "\n",
    "attachments = [\n",
    "    {\n",
    "        \"asset_type\": \"script\",\n",
    "        \"name\": \"my_test_script\",\n",
    "        \"description\": \"attachment for script\",\n",
    "        \"mime\": \"application/text\",\n",
    "        \"object_key\": remote_file_path\n",
    "    }\n",
    "]\n",
    "attachments_json = json.dumps(attachments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Python script asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script id: b464cafb-63c6-4159-a5c2-14034c3c0c0d\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl asset create  --metadata '{metadata_json}' --entity '{entity_json}' --attachments '{attachments_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "script_id = result.s\n",
    "print(\"script id: {}\".format(script_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Running a job<a class=\"anchor\" id=\"part3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to a notebook job, you need to specify the environment in which your script job is to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Runtime 23.1 on Python 3.10\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: rt231py-be7e848d-1a02-4282-b60a-1a728cd9cb70\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create a script job. To do this, you need to give your script job a name, a description, and pass the script ID and environment ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"cpdctl-test-job-for-script\"\n",
    "job = {\n",
    "    'asset_ref': script_id, \n",
    "    'configuration': {\n",
    "        'env_id': env_id, \n",
    "        'env_variables': [\n",
    "            'foo=1', \n",
    "            'bar=2'\n",
    "        ]\n",
    "    }, \n",
    "    'description': 'my script job', \n",
    "    'name': job_name\n",
    "}\n",
    "job_json = json.dumps(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job id: cf7fa3c3-b9a0-48ca-b52f-c00e8352a637\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job create --job '{job_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "job_id = result.s\n",
    "print(\"job id: {}\".format(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your script job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run = {\n",
    "    'configuration': {\n",
    "        'env_variables': [\n",
    "            'key1=value1', \n",
    "            'key2=value2'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "job_run_json = json.dumps(job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 3f6050e7-decf-4dd9-bd16-043ec246849c\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job run create --project-id {project_id} --job-id {job_id} --job-run '{job_run_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "run_id = result.s\n",
    "print(\"run id: {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show your script job run logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cpdctl job run logs --job-id {job_id} --run-id {run_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demo 3: Downloading a notebook and uploading it to another project <a class=\"anchor\" id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a notebook in one project and would like to add a specific version of this notebook to another project. To do this, you first need to download the notebook file to your local system and then upload it to the other project. After that you need to create a notebook asset in your project by referencing the uploaded notebook file (.ipynb) and specifying the environment in which your notebook is to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Downloading a notebook <a class=\"anchor\" id=\"part4.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select which notebook version you want to download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List notebook versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mCreated\u001b[0m\n",
      "\u001b[36;1m1aa9f73f-fcdd-41d0-bbbb-64105c8ee369\u001b[0m   1701802812862\n"
     ]
    }
   ],
   "source": [
    "! cpdctl notebook version list --notebook-id {notebook_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the path in the storage volume to the notebook version that you want to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version id: 1aa9f73f-fcdd-41d0-bbbb-64105c8ee369\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version list --notebook-id {notebook_id} --output json -j \"(resources[].metadata.guid)[0]\" --raw-output\n",
    "version_id = result.s\n",
    "print(\"version id: {}\".format(version_id))\n",
    "\n",
    "# You can also specify your version id directly:\n",
    "# env_id = \"Your version ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version storage path: notebook/attachment_for_notebook_a8f8c4de_dad8_430e_86f7_423fbb862a42_1ay0zvvwelhqqbvxd9nlrc1wo.ipynb\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version get --notebook-id {notebook_id} --version-id {version_id} --output json -j \"entity.file_reference\" --raw-output\n",
    "version_storage_path = result.s\n",
    "print(\"version storage path: {}\".format(version_storage_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the noteboook asset with the specific version from the storage path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n",
      "Output written to my-new-notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "file_name = \"my-new-notebook.ipynb\"\n",
    "\n",
    "! cpdctl asset file download --path {version_storage_path} --output-file {file_name} --project-id {project_id} --raw-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Uploading the notebook to another project <a class=\"anchor\" id=\"part4.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the ID of the project to which you want to upload your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another project id: 277c4bc5-2665-49fc-b33d-ce17fe9610fd\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl project list --output json -j \"(resources[].metadata.guid)[1]\" --raw-output\n",
    "project2_id = result.s\n",
    "print(\"another project id: {}\".format(project2_id))\n",
    "\n",
    "# You can also specify your another project id directly:\n",
    "# project2_id = \"Your another project ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the notebook file to this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "remote_file_path = \"notebook/{}\".format(file_name)\n",
    "\n",
    "! cpdctl asset file upload --path {remote_file_path} --file {file_name} --project-id {project2_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have uploaded the notebook file to the project, you need to specify the environment in which to run the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"Runtime 23.1 on Python 3.10\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: rt231py-277c4bc5-2665-49fc-b33d-ce17fe9610fd\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project2_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create a notebook asset in this project by referencing the uploaded notebook file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"my-new-notebook-in-another-project.ipynb\"\n",
    "runtime = {\n",
    "    'environment': env_id\n",
    "}\n",
    "runtime_json = json.dumps(runtime)\n",
    "originate = {\n",
    "    'type': 'blank'\n",
    "}\n",
    "originate_json = json.dumps(originate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook id: 09348013-24cc-4ba8-8dad-e74f11d72120\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook create --file-reference {remote_file_path} --name {file_name} --project-id {project2_id} --originates-from '{originate_json}' --runtime '{runtime_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "notebook_id = result.s\n",
    "print(\"notebook id: {}\".format(notebook_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demo 4: Adding additional packages for custom environment <a class=\"anchor\" id=\"part5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a `conda-yml` file that lists your additional packages **or** you have a `pip-zip` file containing your custom packages, and you would like to install these packages in your custom environment. To do this, you need to:\n",
    "\n",
    "- Create a custom software specification\n",
    "- Add your custom packages\n",
    "- Create a custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creating a custom software specification <a class=\"anchor\" id=\"part5.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a custom software specification, you need to specify the base software specification that you want to customize. You can list all the software specifications in your project and choose one of them as the base software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                              \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m                                          \u001b[1mType\u001b[0m\n",
      "\u001b[36;1m0062b8c9-8b7d-44a0-a9b9-46c416adcbd9\u001b[0m   default_py3.6                     2023-10-22T10:50:09.912Z   Default Python 3.6                                   software_specification\n",
      "\u001b[36;1m018ebea5-1d1f-5fec-b93e-5e2ab30e7f38\u001b[0m   runtime-22.1-r3.6                 2023-10-22T10:50:09.934Z   Software specification for IBM Runtime 22.1 on R …   software_specification\n",
      "\u001b[36;1m01ce9391-1a79-5a33-94fb-2e134337f314\u001b[0m   autoai-ts_rt23.1-py3.10           2023-10-22T10:50:09.900Z   AutoAI-TimeSeries on Runtime 23.1 with Python 3.10   software_specification\n",
      "\u001b[36;1m020d69ce-7ac1-5e68-ac1a-31189867356a\u001b[0m   kernel-spark3.2-scala2.12         2023-10-22T10:50:09.905Z   Jupyter kernel on Scala 2.12 with Spark 3.2          software_specification\n",
      "\u001b[36;1m067048c7-c771-5933-9aa0-4f9fbdc92da8\u001b[0m   tensorflow_rt23.1-py3.10-edt      2023-10-22T10:50:09.999Z   Tensorflow 2.12 Elastic Distributed Training on I…   software_specification\n",
      "\u001b[36;1m069ea134-3346-5748-b513-49120e15d288\u001b[0m   pytorch-onnx_1.3-py3.7-edt        2023-10-22T10:50:09.922Z   Software specification for Pytorch 1.3.1 Elastic …   software_specification\n",
      "\u001b[36;1m079a91e0-245f-5269-8926-3c20b28f37dc\u001b[0m   tensorflow_rt23.1-py3.10          2023-10-22T10:50:09.999Z   Tensorflow 2.12 on IBM Runtime 23.1 with Python 3…   software_specification\n",
      "\u001b[36;1m09c5a1d0-9c1e-4473-a344-eb7b665ff687\u001b[0m   scikit-learn_0.20-py3.6           2023-10-22T10:50:09.915Z   Software specification for Scikit-learn on Python…   software_specification\n",
      "\u001b[36;1m09f4cff0-90a7-5899-b9ed-1ef348aebdee\u001b[0m   spark-mllib_3.0-scala_2.12        2023-10-22T10:50:09.996Z   Machine Learning on Spark 3.0 with Scala 2.12        software_specification\n",
      "\u001b[36;1m0b848dd4-e681-5599-be41-b5f6fccc6471\u001b[0m   pytorch-onnx_rt22.1-py3.9         2023-10-22T10:50:09.928Z   Software specification for Pytorch 1.10.1 on IBM …   software_specification\n",
      "\u001b[36;1m0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda\u001b[0m   ai-function_0.1-py3.6             2023-10-22T10:50:09.910Z   Software specification for AI function on Python …   software_specification\n",
      "\u001b[36;1m0e6e79df-875e-4f24-8ae9-62dcc2148306\u001b[0m   shiny-r3.6                        2023-10-22T10:50:09.930Z   R 3.6 with Shiny                                     software_specification\n",
      "\u001b[36;1m10ac12d6-6b30-4ccd-8392-3e922c096a92\u001b[0m   pytorch_1.1-py3.6                 2023-10-22T10:50:09.913Z   Software specification for Pytorch on Python 3.6     software_specification\n",
      "\u001b[36;1m125b6d9a-5b1f-5e8d-972a-b251688ccf40\u001b[0m   autoai-kb_rt22.2-py3.10           2023-11-24T17:50:12.922Z   Software specification for AutoAI KaggleBot on Ru…   software_specification\n",
      "\u001b[36;1m129aec82-7e65-5c78-b812-4c0a74b916f5\u001b[0m   watsonx-textgen-fm-1.0            2023-10-22T10:50:09.999Z   Foundation Models 1.0                                software_specification\n",
      "\u001b[36;1m12b83a17-24d8-5082-900f-0ab31fbfd3cb\u001b[0m   runtime-22.1-py3.9                2023-10-22T10:50:09.933Z   Software specification for IBM Runtime 22.1 on Py…   software_specification\n",
      "\u001b[36;1m13666829-5570-53a7-927b-52d42a101d93\u001b[0m   masking-flows-spark               2023-10-22T10:50:09.909Z   Masking Flow Spark                                   software_specification\n",
      "\u001b[36;1m147e6777-ccd1-5886-8571-5356abc20839\u001b[0m   kernel-spark3.3-py3.10            2023-10-22T10:50:09.905Z   Jupyter kernel on Python 3.10 with Spark 3.3         software_specification\n",
      "\u001b[36;1m154010fa-5b3b-4ac1-82af-4d5ee5abbc85\u001b[0m   scikit-learn_0.22-py3.6           2023-10-22T10:50:09.916Z   Software specification for Scikit-learn on Python…   software_specification\n",
      "\u001b[36;1m170df6be-4c83-54a2-a57a-617ab7ebfc92\u001b[0m   tensorflow_rt23.1-py3.10-dist     2023-10-22T10:50:09.998Z   Tensorflow 2.12 Native Distributed Training on IB…   software_specification\n",
      "\u001b[36;1m195067e6-4c5e-5fab-8bd0-e7623a88b4d3\u001b[0m   pytorch-onnx_rt23.1-py3.10        2023-10-22T10:50:09.930Z   Pytorch 2.0 on IBM Runtime 23.1 with Python 3.10     software_specification\n",
      "\u001b[36;1m1b199910-c7d5-5af4-b8f1-e86b760f9779\u001b[0m   pytorch-onnx_1.7-py3.8-edt        2023-10-22T10:50:09.927Z   Software specification for Pytorch 1.7 Elastic Di…   software_specification\n",
      "\u001b[36;1m1b70aec3-ab34-4b87-8aa0-a4a3c8296a36\u001b[0m   default_r3.6                      2023-10-22T10:50:09.930Z   Default R 3.6                                        software_specification\n",
      "\u001b[36;1m1c9e5454-f216-59dd-a20e-474a5cdf5988\u001b[0m   kernel-spark3.3-r3.6              2023-10-22T10:50:09.907Z   Jupyter kernel on R 3.6 with Spark 3.3               software_specification\n",
      "\u001b[36;1m1d362186-7ad5-5b59-8b6c-9d0880bde37f\u001b[0m   pytorch-onnx_rt22.1-py3.9-edt     2023-10-22T10:50:09.928Z   Software specification for Pytorch 1.10.1 Elastic…   software_specification\n",
      "\u001b[36;1m20047f72-0a98-58c7-9ff5-a77b012eb8f5\u001b[0m   spark-mllib_3.2                   2023-10-22T10:50:09.936Z   Machine Learning on Spark 3.2                        software_specification\n",
      "\u001b[36;1m26215f05-08c3-5a41-a1b0-da66306ce658\u001b[0m   runtime-22.1-py3.9-cuda           2023-10-22T10:50:09.933Z   Software specification for IBM Runtime 22.1 on Py…   software_specification\n",
      "\u001b[36;1m295addb5-9ef9-547e-9bf4-92ae3563e720\u001b[0m   do_py3.8                          2023-10-22T10:50:09.927Z   Python 3.8 with Decision Optimization                software_specification\n",
      "\u001b[36;1m2aa0c932-798f-5ae9-abd6-15e0c2402fb5\u001b[0m   autoai-ts_3.8-py3.8               2023-10-22T10:50:09.925Z   Software specification for AutoAI TimeSeries on P…   software_specification\n",
      "\u001b[36;1m2b73a275-7cbf-420b-a912-eae7f436e0bc\u001b[0m   tensorflow_1.15-py3.6             2023-10-22T10:50:09.916Z   Software specification for Tensorflow on Python 3…   software_specification\n",
      "\u001b[36;1m2b7961e2-e3b1-5a8c-a491-482c8368839a\u001b[0m   kernel-spark3.3-py3.9             2023-10-22T10:50:09.906Z   Jupyter kernel on Python 3.9 with Spark 3.3          software_specification\n",
      "\u001b[36;1m2c8ef57d-2687-4b7d-acce-01f94976dac1\u001b[0m   pytorch_1.2-py3.6                 2023-10-22T10:50:09.913Z   Software specification for Pytorch on Python 3.6     software_specification\n",
      "\u001b[36;1m2e51f700-bca0-4b0d-88dc-5c6791338875\u001b[0m   spark-mllib_2.3                   2023-10-22T10:50:09.937Z   Machine Learning on Spark 2.3 with Python 3.6        software_specification\n",
      "\u001b[36;1m32983cea-3f32-4400-8965-dde874a8d67e\u001b[0m   pytorch-onnx_1.1-py3.6-edt        2023-10-22T10:50:09.913Z   Software specification for Pytorch EDT with ONNX …   software_specification\n",
      "\u001b[36;1m336b29df-e0e1-5e7d-b6a5-f6ab722625b2\u001b[0m   runtime-23.1-py3.10               2023-11-20T22:10:10.096Z   Runtime 23.1 on Python 3.10                          software_specification\n",
      "\u001b[36;1m36507ebe-8770-55ba-ab2a-eafe787600e9\u001b[0m   spark-mllib_3.0-py37              2023-10-22T10:50:09.994Z   Machine Learning on Spark 3.0 with Python 3.7        software_specification\n",
      "\u001b[36;1m367f7fa5-e4f7-50c5-9f57-3e831be5bb89\u001b[0m   pytorch-onnx_rt23.1-py3.10-edt    2023-10-22T10:50:09.930Z   Pytorch 2.0 Elastic Distributed Training on IBM R…   software_specification\n",
      "\u001b[36;1m396b2e83-0953-5b86-9a55-7ce1628a406f\u001b[0m   autoai-ts_rt22.2-py3.10           2023-11-24T17:50:12.924Z   Software specification for AutoAI-TimeSeries on R…   software_specification\n",
      "\u001b[36;1m39e31acd-5f30-41dc-ae44-60233c80306e\u001b[0m   xgboost_0.82-py3.6                2023-10-22T10:50:09.917Z   Software specification for XGBoost on Python 3.6     software_specification\n",
      "\u001b[36;1m40589d0e-7019-4e28-8daa-fb03b6f4fe12\u001b[0m   pytorch-onnx_1.2-py3.6-edt        2023-10-22T10:50:09.913Z   Software specification for Pytorch EDT with ONNX …   software_specification\n",
      "\u001b[36;1m40e73f55-783a-5535-b3fa-0c8b94291431\u001b[0m   pytorch-onnx_rt22.2-py3.10        2023-11-24T17:50:12.927Z   Software specification for Pytorch 1.12 on Runtim…   software_specification\n",
      "\u001b[36;1m4269d26e-07ba-5d40-8f66-2d495b0c71f7\u001b[0m   autoai-ts_rt22.1-py3.9            2023-10-22T10:50:09.898Z   Software specification for AutoAI-TimeSeries on I…   software_specification\n",
      "\u001b[36;1m42b92e18-d9ab-567f-988a-4240ba1ed5f7\u001b[0m   autoai-obm_3.0                    2023-10-22T10:50:09.993Z   Software specification for AutoAI OneButtonMachin…   software_specification\n",
      "\u001b[36;1m42c36a39-fcc1-5117-8ff6-1d4523e0d6a6\u001b[0m   rstudio_r4.2                      2023-10-22T10:50:09.931Z   Default R 4.2                                        software_specification\n",
      "\u001b[36;1m435bfa8f-ddae-549a-826a-894368887231\u001b[0m   ai-function_0.2-py3.6             2023-10-22T10:50:09.910Z   Software specification for Python Functions on Py…   software_specification\n",
      "\u001b[36;1m493bcb95-16f1-5bc5-bee8-81b8af80e9c7\u001b[0m   pmml-3.0_4.3                      2023-10-22T10:50:09.909Z   PMML with 3.0 to 4.3                                 software_specification\n",
      "\u001b[36;1m49403dff-92e9-4c87-a3d7-a42d0021c095\u001b[0m   spark-mllib_2.4-r_3.6             2023-10-22T10:50:09.939Z   Machine Learning on Spark 2.4 with R 3.6             software_specification\n",
      "\u001b[36;1m4ff8d6c2-1343-4c18-85e1-689c965304d3\u001b[0m   xgboost_0.90-py3.6                2023-10-22T10:50:09.917Z   Software specification for XGBoost on Python 3.6     software_specification\n",
      "\u001b[36;1m50f95b2a-bc16-43bb-bc94-b0bed208c60b\u001b[0m   pytorch-onnx_1.1-py3.6            2023-10-22T10:50:09.914Z   Software specification for Pytorch with ONNX on P…   software_specification\n",
      "\u001b[36;1m52c57136-80fa-572e-8728-a5e7cbb42cde\u001b[0m   autoai-ts_3.9-py3.8               2023-10-22T10:50:09.925Z   Software specification for AutoAI-TimeSeries on P…   software_specification\n",
      "\u001b[36;1m55a70f99-7320-4be5-9fb9-9edb5a443af5\u001b[0m   spark-mllib_2.4-scala_2.11        2023-10-22T10:50:09.939Z   Machine Learning on Spark 2.4 with Scala 2.11        software_specification\n",
      "\u001b[36;1m5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9\u001b[0m   spark-mllib_3.0                   2023-10-22T10:50:09.937Z   Machine Learning on Spark 3.0                        software_specification\n",
      "\u001b[36;1m5c2e37fa-80b8-5e77-840f-d912469614ee\u001b[0m   autoai-obm_2.0                    2023-10-22T10:50:09.938Z   Software specification for AutoAI OneButtonMachin…   software_specification\n",
      "\u001b[36;1m5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b\u001b[0m   spss-modeler_18.1                 2023-10-22T10:50:09.997Z   SPSS Modeler 18.1                                    software_specification\n",
      "\u001b[36;1m5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e\u001b[0m   cuda-py3.8                        2023-10-22T10:50:09.926Z   Python 3.8 with CUDA                                 software_specification\n",
      "\u001b[36;1m61740dc9-19ed-563c-bbe4-925f38a81478\u001b[0m   pytorch-onnx_rt22.2-py3.10-dist   2023-11-24T17:50:12.925Z   Software specification for Pytorch 1.12 Native Di…   software_specification\n",
      "\u001b[36;1m632d4b22-10aa-5180-88f0-f52dfb6444d7\u001b[0m   autoai-kb_3.1-py3.7               2023-10-22T10:50:09.918Z   Software specification for AutoAI KaggleBot on Py…   software_specification\n",
      "\u001b[36;1m634d3cdc-b562-5bf9-a2d4-ea90a478456b\u001b[0m   pytorch-onnx_1.7-py3.8            2023-10-22T10:50:09.927Z   Software specification for Pytorch 1.3.1 on Pytho…   software_specification\n",
      "\u001b[36;1m65691379-8334-5b81-9d22-a9b77b3c2f8b\u001b[0m   kernel-spark3.3-r4.2              2023-10-22T10:50:09.907Z   Jupyter kernel on R 4.2 with Spark 3.3               software_specification\n",
      "\u001b[36;1m65e171d7-72d1-55d9-8ebb-f813d620c9bb\u001b[0m   tensorflow_2.4-py3.7              2023-10-22T10:50:09.924Z   Software specification for Tensorflow 2.4 on Pyth…   software_specification\n",
      "\u001b[36;1m687eddc9-028a-4117-b9dd-e57b36f1efa5\u001b[0m   spss-modeler_18.2                 2023-10-22T10:50:09.997Z   SPSS Modeler 18.2                                    software_specification\n",
      "\u001b[36;1m692a6a4d-2c4d-45ff-a1ed-b167ee55469a\u001b[0m   pytorch-onnx_1.2-py3.6            2023-10-22T10:50:09.915Z   Software specification for Pytorch with ONNX on P…   software_specification\n",
      "\u001b[36;1m722513c1-b226-5a3d-b5d0-f691185b8695\u001b[0m   tensorflow_rt22.2-py3.10-dist     2023-11-24T17:50:12.928Z   Software specification for Tensorflow 2.9 Native …   software_specification\n",
      "\u001b[36;1m7abc992b-b685-532b-a122-a396a3cdbaab\u001b[0m   spark-mllib_2.4-py37              2023-10-22T10:50:09.939Z   Machine Learning on Spark 2.4 with Python 3.7        software_specification\n",
      "\u001b[36;1m7bb3dbe2-da6e-4145-918d-b6d84aa93b6b\u001b[0m   caffe_1.0-py3.6                   2023-10-22T10:50:09.911Z   Caffe (community) on Python 3.6                      software_specification\n",
      "\u001b[36;1m7fbf1305-59a7-5b77-b881-1416ce2ee903\u001b[0m   rstudio-23.1-r4.2                 2023-10-22T10:50:09.930Z   RStudio with Runtime 23.1 on R 4.2                   software_specification\n",
      "\u001b[36;1m812c6631-42b7-5613-982b-02098e6c909c\u001b[0m   pytorch-onnx_1.7-py3.7            2023-10-22T10:50:09.924Z   Software specification for Pytorch 1.7.1 on Pytho…   software_specification\n",
      "\u001b[36;1m82c79ece-4d12-40e6-8787-a7b9e0f62770\u001b[0m   cuda-py3.6                        2023-10-22T10:50:09.911Z   Python 3.6 with CUDA                                 software_specification\n",
      "\u001b[36;1m8c1a58c6-62b5-4dc4-987a-df751c2756b6\u001b[0m   hybrid_0.1                        2023-10-22T10:50:09.902Z   Watson Machine Learning Hybrid framework             software_specification\n",
      "\u001b[36;1m8d5d8a87-a912-54cf-81ec-3914adaa988d\u001b[0m   pytorch-onnx_1.3-py3.7            2023-10-22T10:50:09.923Z   Software specification for Pytorch 1.3.1 on Pytho…   software_specification\n",
      "\u001b[36;1m8d863266-7927-4d1e-97d7-56a7f4c0a19b\u001b[0m   caffe-ibm_1.0-py3.6               2023-10-22T10:50:09.911Z   Caffe (IBM) on Python 3.6                            software_specification\n",
      "\u001b[36;1m8ef391e4-ef58-5d46-b078-a82c211c1058\u001b[0m   runtime-22.2-py3.10-cuda          2023-11-14T06:55:08.449Z   GPU Runtime 22.2 on Python 3.10                      software_specification\n",
      "\u001b[36;1m902d0051-84bd-4af6-ab6b-8f6aa6fdeabb\u001b[0m   spss-modeler_17.1                 2023-10-22T10:50:09.997Z   SPSS Modeler 17.1                                    software_specification\n",
      "\u001b[36;1m9100fd72-8159-4eb9-8a0b-a87e12eefa36\u001b[0m   do_12.10                          2023-10-22T10:50:09.901Z   Software specification for Decision Optimization     software_specification\n",
      "\u001b[36;1m9447fa8b-2051-4d24-9eef-5acb0e3c59f8\u001b[0m   do_py3.7                          2023-10-22T10:50:09.922Z   (Deprecated) Python 3.7 with Decision Optimization   software_specification\n",
      "\u001b[36;1m94bb6052-c837-589d-83f1-f4142f219e32\u001b[0m   spark-mllib_3.0-r_3.6             2023-10-22T10:50:09.996Z   Machine Learning on Spark 3.0 with R 3.6             software_specification\n",
      "\u001b[36;1m94e9652b-7f2d-59d5-ba5a-23a414ea488f\u001b[0m   cuda-py3.7-opence                 2023-10-22T10:50:09.920Z   Python 3.7 with CUDA                                 software_specification\n",
      "\u001b[36;1m9979f055-703f-5737-b9ca-679772a2e8dc\u001b[0m   kernel-spark3.4-r4.2              2023-11-14T00:40:10.795Z   Jupyter kernel on R 4.2 with Spark 3.4               software_specification\n",
      "\u001b[36;1m9a44990c-1aa1-4c7d-baf8-c4099011741c\u001b[0m   cuda-py3.7                        2023-10-22T10:50:09.920Z   (Deprecated) Python 3.7 with CUDA                    software_specification\n",
      "\u001b[36;1m9b3f9040-9cee-4ead-8d7a-780600f542f7\u001b[0m   hybrid_0.2                        2023-10-22T10:50:09.903Z   Watson Machine Learning Hybrid framework             software_specification\n",
      "\u001b[36;1m9f7a8fc1-4d3c-5e65-ab90-41fa8de2d418\u001b[0m   spark-mllib_3.0-py38              2023-10-22T10:50:09.995Z   Machine Learning on Spark 3.0 with Python 3.8        software_specification\n",
      "\u001b[36;1ma1275ec7-2602-52bd-a193-44ba137265df\u001b[0m   runtime-23.1-r4.2                 2023-11-14T06:55:08.448Z   Runtime 23.1 on R 4.2                                software_specification\n",
      "\u001b[36;1ma1380ce0-5d3c-59ca-9b44-d6bf0739838a\u001b[0m   autoai-tsad_rt22.2-py3.10         2023-11-24T17:50:12.924Z   AutoAI-TimeSeriesAnomalyDetection on IBM Runtime …   software_specification\n",
      "\u001b[36;1ma3515e34-e372-5244-8609-f14713deac9d\u001b[0m   autoai-kb_3.2-py3.7               2023-10-22T10:50:09.918Z   Software specification for AutoAI KaggleBot on Py…   software_specification\n",
      "\u001b[36;1ma545cca3-02df-5c61-9e88-998b09dc79af\u001b[0m   autoai-kb_3.3-py3.7               2023-10-22T10:50:09.918Z   Software specification for AutoAI KaggleBot on Py…   software_specification\n",
      "\u001b[36;1ma6082a27-5acc-5163-b02c-6b96916eb5e0\u001b[0m   spark-mllib_3.0-py39              2023-10-22T10:50:09.936Z   Machine Learning on Spark 3.0 with Python 3.9        software_specification\n",
      "\u001b[36;1ma737ef48-6bb7-59c8-aadf-5c5cccec1e10\u001b[0m   tensorflow_rt22.2-py3.10-edt      2023-11-24T17:50:12.928Z   Software specification for Tensorflow 2.9 Elastic…   software_specification\n",
      "\u001b[36;1mab9e1b80-f2ce-592c-a7d2-4f2344f77194\u001b[0m   default_py3.8                     2023-10-22T10:50:09.926Z   Default Python 3.8                                   software_specification\n",
      "\u001b[36;1macd9c798-6974-5d2f-a657-ce06e986df4d\u001b[0m   tensorflow_rt22.1-py3.9           2023-10-22T10:50:09.998Z   Software specification for Tensorflow 2.7 on IBM …   software_specification\n",
      "\u001b[36;1mad7033ee-794e-58cf-812e-a95f4b64b207\u001b[0m   kernel-spark3.2-py3.9             2023-10-22T10:50:09.903Z   Jupyter kernel on Python 3.9 with Spark 3.2          software_specification\n",
      "\u001b[36;1maf10f35f-69fa-5d66-9bf5-acb58434263a\u001b[0m   autoai-obm_2.0 with Spark 3.0     2023-10-22T10:50:09.992Z   Software specification for AutoAI OneButtonMachin…   software_specification\n",
      "\u001b[36;1mb4246d87-d8b3-5621-9fea-76a8ea452616\u001b[0m   autoai-kb_rt23.1-py3.10           2023-10-22T10:50:09.896Z   AutoAI-KaggleBot on Runtime 23.1 with Python 3.10    software_specification\n",
      "\u001b[36;1mb4c13f57-a6dc-5d31-b8b2-d433eec8342f\u001b[0m   pytorch-onnx_rt23.1-py3.10-dist   2023-10-22T10:50:09.929Z   Pytorch 2.0 Native Distributed Training on IBM Ru…   software_specification\n",
      "\u001b[36;1mb56101f1-309d-549b-a849-eaa63f77b2fb\u001b[0m   runtime-22.2-py3.10               2023-11-24T17:50:12.927Z   Runtime 22.2 on Python 3.10                          software_specification\n",
      "\u001b[36;1mc2057dd4-f42c-5f77-a02f-72bdbd3282c9\u001b[0m   default_py3.7_opence              2023-10-22T10:50:09.921Z   Default Python 3.7                                   software_specification\n",
      "\u001b[36;1mc4032338-2a40-500a-beef-b01ab2667e27\u001b[0m   tensorflow_2.1-py3.7              2023-10-22T10:50:09.924Z   Software specification for Tensorflow 2.1 on Pyth…   software_specification\n",
      "\u001b[36;1mcc8f8976-b74a-551a-bb66-6377f8d865b4\u001b[0m   do_py3.7_opence                   2023-10-22T10:50:09.922Z   Python 3.7 with Decision Optimization                software_specification\n",
      "\u001b[36;1mcd3c730f-bc13-594f-9510-002634662e8b\u001b[0m   autoai-tsad_rt23.1-py3.10         2023-10-22T10:50:09.901Z   AutoAI-TimeSeriesAnomalyDetection on Runtime 23.1…   software_specification\n",
      "\u001b[36;1md11f2434-4fc7-58b7-8a62-755da64fdaf8\u001b[0m   spark-mllib_3.3                   2023-10-22T10:50:09.937Z   Machine Learning on Spark 3.3                        software_specification\n",
      "\u001b[36;1md139f196-e04b-5d8b-9140-9a10ca1fa91a\u001b[0m   autoai-kb_3.0-py3.6               2023-10-22T10:50:09.910Z   Software specification for AutoAI KaggleBot on Py…   software_specification\n",
      "\u001b[36;1md82546d5-dd78-5fbb-9131-2ec309bc56ed\u001b[0m   spark-mllib_3.0-py36              2023-10-22T10:50:09.993Z   Machine Learning on Spark 3.0 with Python 3.6        software_specification\n",
      "\u001b[36;1mda9b39c3-758c-5a4f-9cfd-457dd4d8c395\u001b[0m   autoai-kb_3.4-py3.8               2023-10-22T10:50:09.925Z   Software specification for AutoAI KaggleBot on Py…   software_specification\n",
      "\u001b[36;1mdb2fe4d6-d641-5d05-9972-73c654c60e0a\u001b[0m   kernel-spark3.2-r3.6              2023-10-22T10:50:09.904Z   Jupyter kernel on R 3.6 with Spark 3.2               software_specification\n",
      "\u001b[36;1mdb6afe93-665f-5910-b117-d879897404d9\u001b[0m   autoai-kb_rt22.1-py3.9            2023-10-22T10:50:09.894Z   Software specification for AutoAI KaggleBot (Pyth…   software_specification\n",
      "\u001b[36;1mdeef04f0-0c42-5147-9711-89f9904299db\u001b[0m   autoai-ts_1.0-py3.7               2023-10-22T10:50:09.919Z   Software specification for AutoAI-TimeSeries on P…   software_specification\n",
      "\u001b[36;1me384fce5-fdd1-53f8-bc71-11326c9c635f\u001b[0m   tensorflow_2.1-py3.7-horovod      2023-10-22T10:50:09.924Z   Software specification for Tensorflow 2.1 on Pyth…   software_specification\n",
      "\u001b[36;1me441dfdb-bcd1-5310-9da4-906127712abf\u001b[0m   spark-mllib_3.0-py39              2023-10-22T10:50:09.995Z   Machine Learning on Spark 3.0 with Python 3.9        software_specification\n",
      "\u001b[36;1me4429883-c883-42b6-87a8-f419d64088cd\u001b[0m   default_py3.7                     2023-10-22T10:50:09.921Z   (Deprecated) Default Python 3.7                      software_specification\n",
      "\u001b[36;1me51999ba-6452-5f1f-8287-17228b88b652\u001b[0m   do_22.1                           2023-10-22T10:50:09.902Z   Software specification for Decision Optimization     software_specification\n",
      "\u001b[36;1mea43a235-ec09-5b09-b38e-312a8a7086cc\u001b[0m   kernel-spark3.4-py3.10            2023-11-14T00:40:10.793Z   Jupyter kernel on Python 3.10 with Spark 3.4         software_specification\n",
      "\u001b[36;1meae86aab-da30-5229-a6a6-1d0d4e368983\u001b[0m   autoai-obm_3.2                    2023-10-22T10:50:09.898Z   Software specification for AutoAI OneButtonMachin…   software_specification\n",
      "\u001b[36;1mec0a3d28-08f7-556c-9674-ca7c2dba30bd\u001b[0m   runtime-22.2-r4.2                 2023-11-14T06:55:08.450Z   Runtime 22.2 on R 4.2                                software_specification\n",
      "\u001b[36;1mef1726a6-c84f-5a2c-aac6-5b80e39b8af0\u001b[0m   pytorch-onnx_1.7-py3.7-edt        2023-10-22T10:50:09.923Z   Software specification for Pytorch 1.7 Elastic Di…   software_specification\n",
      "\u001b[36;1mf31eb7d1-a784-5a74-a40b-579989aacfcb\u001b[0m   runtime-23.1-py3.10-cuda          2023-11-20T22:10:10.094Z   GPU Runtime 23.1 on Python 3.10                      software_specification\n",
      "\u001b[36;1mf65bd165-f057-55de-b5cb-f97cf2c0f393\u001b[0m   tensorflow_rt22.2-py3.10          2023-11-24T17:50:12.929Z   Software specification for Tensorflow 2.9 on Runt…   software_specification\n",
      "\u001b[36;1mf686cdd9-7904-5f9d-a732-01b0d6b10dc5\u001b[0m   do_20.1                           2023-10-22T10:50:09.902Z   Software specification for Decision Optimization     software_specification\n",
      "\u001b[36;1mf8a05d07-e7cd-57bb-a10b-23f1d4b837ac\u001b[0m   pytorch-onnx_rt22.2-py3.10-edt    2023-11-24T17:50:12.926Z   Software specification for Pytorch 1.12.0 Elastic…   software_specification\n",
      "\u001b[36;1mfe185c44-9a99-5425-986b-59bd1d2eda46\u001b[0m   tensorflow_2.4-py3.8              2023-10-22T10:50:09.927Z   Software specification for Tensorflow 2.4 on Pyth…   software_specification\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment software-specification list --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base software specification id: 336b29df-e0e1-5e7d-b6a5-f6ab722625b2\n"
     ]
    }
   ],
   "source": [
    "base_sw_spec_name = \"Runtime 23.1 on Python 3.10\"\n",
    "query_string = \"(resources[?metadata.description == '{}'].metadata.asset_id)[0]\".format(base_sw_spec_name)\n",
    "\n",
    "result = ! cpdctl environment software-specification list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "base_sw_spec_id = result.s\n",
    "print(\"base software specification id: {}\".format(base_sw_spec_id))\n",
    "\n",
    "# You can also specify your base software specification id directly:\n",
    "# based_sw_spec_id = \"Your base software specification ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sw_spec_name = \"my_sw_spec\"\n",
    "\n",
    "base_sw_spec = {\n",
    "    'guid': base_sw_spec_id\n",
    "}\n",
    "\n",
    "base_sw_spec_json = json.dumps(base_sw_spec)\n",
    "\n",
    "sw_conf = {}\n",
    "sw_conf_json = json.dumps(sw_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom software specification id: e0910504-cc78-4f93-90ac-a1f4f321923c\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment software-specification create --project-id {project_id} --name {custom_sw_spec_name} --base-software-specification '{base_sw_spec_json}' --software-configuration '{sw_conf_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "custom_sw_spec_id = result.s\n",
    "print(\"custom software specification id: {}\".format(custom_sw_spec_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Adding additional packages <a class=\"anchor\" id=\"part5.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a package extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_name = \"my_test_packages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package extension id: 58a2beda-2c3b-4c0c-9379-fe7977fc54e6\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment package-extension create --name {pkg_name} --type \"conda_yml\" --project-id {project_id}  --output json\n",
    "pkg_ext_id = json.loads(result.s)['metadata']['asset_id']\n",
    "print(\"package extension id: {}\".format(pkg_ext_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the path to where you want to upload the additional packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path where asset should be uploaded: package_extension/my_test_packages_coY9oEMYz.yml\n"
     ]
    }
   ],
   "source": [
    "pkg_ext_href = json.loads(result.s)['entity']['package_extension']['href'].split('/')[4].split('?')[0]\n",
    "remote_pkg_path = \"package_extension/{}\".format(pkg_ext_href)\n",
    "print(\"path where asset should be uploaded: {}\".format(remote_pkg_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a conda-yaml file listing additional packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_yaml = \"\"\"\n",
    "channels:\n",
    "  - defaults\n",
    "\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - fuzzywuzzy\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('my-pkg-ext.yaml', 'w') as f:\n",
    "    f.write(my_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload additional packages to the path returned in the previous command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_pkg_path = \"./my-pkg-ext.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path \"{remote_pkg_path}\" --file {local_pkg_path} --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment package-extension upload-complete --package-extension-id {pkg_ext_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the package extension into the custom software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment software-specification add-package-extensions --software-specification-id {custom_sw_spec_id} --package-extension-id {pkg_ext_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Creating a custom environment <a class=\"anchor\" id=\"part5.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the hardware specifications in your project and choose one that fits your custom environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                     \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m                                          \u001b[1mType\u001b[0m\n",
      "\u001b[36;1m3c48c595-a6eb-5a38-bae1-7fea3f366162\u001b[0m   CPUx2                    2023-10-22T10:50:11.641Z   2 CPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1m5611c0b6-704a-5913-8766-60cbaedf5c68\u001b[0m   GPUx1                    2023-10-22T10:50:11.642Z   1 GPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1m5a1f0e64-e420-55ce-bd7a-f6d00bb942cf\u001b[0m   ML                       2023-10-22T10:50:11.645Z   A hardware specification providing 4 CPU cores an…   hardware_specification\n",
      "\u001b[36;1m7b6a7c67-0727-5ff9-885e-cf3bb78ea3e2\u001b[0m   GPUx2                    2023-10-22T10:50:11.642Z   2 GPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1m8d211f8f-1ea1-5154-8e64-377521ab566e\u001b[0m   GPUx4                    2023-10-22T10:50:11.642Z   4 GPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1m93a39616-868b-55b4-ad23-2c09a1236a01\u001b[0m   Notebook Default         2023-10-22T10:50:11.646Z   For notebooks. The default resource sizes are sub…   hardware_specification\n",
      "\u001b[36;1ma02f3ab5-6964-4f06-a870-c7cc69187895\u001b[0m   V100x2                   2023-10-22T10:50:11.646Z   2 V100 GPU for WML-A                                 hardware_specification\n",
      "\u001b[36;1ma6c4923b-b8e4-444c-9f43-8a7ec3020110\u001b[0m   L                        2023-10-22T10:50:11.645Z   A hardware specification providing 8 CPU cores an…   hardware_specification\n",
      "\u001b[36;1mac59d20a-9c7c-4504-a853-788ef35969da\u001b[0m   Default Spark            2023-10-22T10:50:11.642Z   A hardware specification for Spark with 1 CPU and…   hardware_specification\n",
      "\u001b[36;1mb128f957-581d-46d0-95b6-8af5cd5be580\u001b[0m   XXS                      2023-10-22T10:50:11.647Z   A hardware specification providing one CPU core a…   hardware_specification\n",
      "\u001b[36;1mb17e604a-5a56-52d9-abd1-45af9718c8af\u001b[0m   JupyterLab Default       2023-10-22T10:50:11.643Z   For JupyterLab. The default resource sizes are su…   hardware_specification\n",
      "\u001b[36;1mb2232f7a-bfad-4822-9bce-6ba1af49217a\u001b[0m   M-Spark                  2023-10-22T10:50:11.645Z   A hardware specification for Spark service with 2…   hardware_specification\n",
      "\u001b[36;1mb305a34b-acb5-4850-a44a-f1f15e304a20\u001b[0m   V100x4                   2023-10-22T10:50:11.646Z   4 V100 GPU for WML-A                                 hardware_specification\n",
      "\u001b[36;1mb37eae80-df2b-594b-9712-6854e9dc1a97\u001b[0m   CPUx4                    2023-10-22T10:50:11.641Z   4 CPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1mbc40cab2-70d7-594a-a723-7ab1cdef7adc\u001b[0m   CPUx1                    2023-10-22T10:50:11.640Z   1 CPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1mc076e82c-b2a7-4d20-9c0f-1f0c2fdf5a24\u001b[0m   M                        2023-10-22T10:50:11.645Z   A hardware specification providing 4 CPU cores an…   hardware_specification\n",
      "\u001b[36;1mc1791762-1333-4dd3-b7bb-228ae287da31\u001b[0m   XL-Spark                 2023-10-22T10:50:11.647Z   A hardware specification for Spark service with 3…   hardware_specification\n",
      "\u001b[36;1mc4293bb1-275b-5423-af82-e9018a8b321a\u001b[0m   GPUx3                    2023-10-22T10:50:11.642Z   3 GPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1mcf70f086-916d-4684-91a7-264c49c6d425\u001b[0m   K80                      2023-10-22T10:50:11.644Z   1 K80 GPU for WML-A                                  hardware_specification\n",
      "\u001b[36;1md0aa1ae8-a889-42e2-a099-041b604b9289\u001b[0m   XL                       2023-10-22T10:50:11.647Z   A hardware specification providing 16 CPU cores a…   hardware_specification\n",
      "\u001b[36;1md0f52aa1-4312-40f6-ad84-f16cf5c6da9e\u001b[0m   K80x2                    2023-10-22T10:50:11.644Z   2 K80 GPU for WML-A                                  hardware_specification\n",
      "\u001b[36;1md4a59ab5-7ef6-5eb2-8854-68e88ad52b80\u001b[0m   CPUx3                    2023-10-22T10:50:11.641Z   3 CPU, for WML deep learning                         hardware_specification\n",
      "\u001b[36;1md4e4937c-a7a5-5357-ad12-45ee7b1ff380\u001b[0m   Notebook Default Spark   2023-10-22T10:50:11.645Z   For notebooks with Spark kernels. The default res…   hardware_specification\n",
      "\u001b[36;1md92943ba-9f47-407d-9280-c85281687a1e\u001b[0m   S-Spark                  2023-10-22T10:50:11.646Z   A hardware specification for Spark service with 1…   hardware_specification\n",
      "\u001b[36;1me18b1866-e8fa-49c8-9aa5-dfaaed6ffa43\u001b[0m   XS-Spark                 2023-10-22T10:50:11.647Z   A hardware specification for Spark with 1 CPU and…   hardware_specification\n",
      "\u001b[36;1me7ed1d6c-2e89-42d7-aed5-863b972c1d2b\u001b[0m   S                        2023-10-22T10:50:11.646Z   A hardware specification providing 2 CPU cores an…   hardware_specification\n",
      "\u001b[36;1mec104857-0389-4649-af8e-971fc11982d0\u001b[0m   K80x4                    2023-10-22T10:50:11.644Z   4 K80 GPU for WML-A                                  hardware_specification\n",
      "\u001b[36;1mf132f14a-6c0f-4570-b87c-98ad1e297953\u001b[0m   L-Spark                  2023-10-22T10:50:11.645Z   A hardware specification for Spark service with 2…   hardware_specification\n",
      "\u001b[36;1mf327bdf7-5634-43d8-b1e3-445afeaf18b9\u001b[0m   V100                     2023-10-22T10:50:11.646Z   1 V100 GPU for WML-A                                 hardware_specification\n",
      "\u001b[36;1mf3ebac7d-0a75-410c-8b48-a931428cc4c5\u001b[0m   XS                       2023-10-22T10:50:11.647Z   A hardware specification providing one CPU core a…   hardware_specification\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment hardware-specification list --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hardware specification id: f3ebac7d-0a75-410c-8b48-a931428cc4c5\n"
     ]
    }
   ],
   "source": [
    "hw_spec_keyword_1 = \"one CPU core\"\n",
    "hw_spec_keyword_2 = \"4 GiB of memory\"\n",
    "query_string = \"(resources[?contains(metadata.description, '{}') && contains(metadata.description, '{}')].metadata.asset_id)[0]\".format(hw_spec_keyword_1, hw_spec_keyword_2)\n",
    "\n",
    "result = ! cpdctl environment hardware-specification list --project-id {project_id}  --output json -j \"{query_string}\" --raw-output\n",
    "hw_spec_id = result.s\n",
    "print(\"hardware specification id: {}\".format(hw_spec_id))\n",
    "\n",
    "# You can also specify your hardware specification id directly:\n",
    "# hw_spec_id = \"Your base software specification ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the ID of a runtime definition which matches the base software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime_definition id: a1e0c491-2695-505d-9a9a-8a04ed215825\n"
     ]
    }
   ],
   "source": [
    "runtime_definition_description = \"Runtime 23.1 on Python 3.10\"\n",
    "query_string = \"(resources[?entity.description == '{}'].metadata.guid)[0]\".format(runtime_definition_description)\n",
    "result = ! cpdctl environment runtime-definition list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "runtime_definition_id = result.s\n",
    "print(\"runtime_definition id: {}\".format(runtime_definition_id))\n",
    "\n",
    "# You can also specify your runtime definition id directly:\n",
    "# env_id = \"Your runtime definition ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom environment by specifying the hardware specification, the custom software specification and the tool specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"my_custom_env\"\n",
    "hw_spec = {\n",
    "    'guid': hw_spec_id\n",
    "}\n",
    "custom_sw_spec = {\n",
    "    'guid': custom_sw_spec_id\n",
    "}\n",
    "custom_sw_spec_json = json.dumps(custom_sw_spec)\n",
    "tool_spec = {\n",
    "    'supported_kernels': [{\n",
    "        'language': 'python', \n",
    "        'version': '3.10', \n",
    "        'display_name': 'Python 3.10'\n",
    "    }]\n",
    "}\n",
    "hw_spec_json = json.dumps(hw_spec)\n",
    "tool_spec_json = json.dumps(tool_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom environment id: a3848af5-602f-4edc-b56d-899faffad5d2\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment create --project-id {project_id} --type \"notebook\" --name {env_name} --display-name {env_name} --hardware-specification '{hw_spec_json}' --software-specification '{custom_sw_spec_json}' --tools-specification '{tool_spec_json}' --runtime-definition {runtime_definition_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "custom_env_id = result.s\n",
    "print(\"custom environment id: {}\".format(custom_env_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use this custom environment when you create a new notebook asset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
